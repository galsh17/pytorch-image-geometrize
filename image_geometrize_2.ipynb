{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_geometrize_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install kornia\n",
        "import kornia"
      ],
      "metadata": {
        "id": "VU2AcsC_3cT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDHMmohJ2Dql"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn, Tensor\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import tqdm\n",
        "import numpy as np\n",
        "from urllib.request import urlopen\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "6V82b2jqALjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow_tensor(img, title=''):\n",
        "  plt.imshow(img[0, 0,:,:].to('cpu'), vmin=0, vmax=1)\n",
        "  plt.title(title)\n",
        "  plt.axis(False)\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "hTFUDSv_gAcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def url_to_tensor(url, readFlag=cv2.IMREAD_COLOR):\n",
        "    # download the image, convert it to a NumPy array, and then read\n",
        "    # it into OpenCV format\n",
        "    resp = urlopen(url)\n",
        "    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "    image = cv2.imdecode(image, readFlag)\n",
        "\n",
        "    # return the image\n",
        "    image: torch.Tensor = kornia.utils.image_to_tensor(image)  # CxHxW\n",
        "    image = image[None,...].float() / 255.\n",
        "    image = kornia.color.bgr_to_rgb(image)\n",
        "    return image.to(device)"
      ],
      "metadata": {
        "id": "9j6fDlgR2IZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_cricle(size, wh):\n",
        "  x, y = torch.meshgrid(torch.arange(0, size[2]).to(device), torch.arange(0, size[3]).to(device))\n",
        "  x = x.to(torch.float32)\n",
        "  y = y.to(torch.float32)\n",
        "  circle = 1 - 2*(((x - size[2]/2)**2) / wh[0]**2 + ((y - size[3]/2)**2 / wh[1]**2))\n",
        "  circle[circle>0] = 1\n",
        "  circle[circle<0] = 0\n",
        "  return circle\n",
        "\n",
        "def translate_shape_img(img, dx, dy, rotation, scale=None):\n",
        "  angle: torch.tensor = torch.ones(1, requires_grad=True).to(device) * rotation\n",
        "  center: torch.tensor = torch.ones(1, 2).to(device)\n",
        "  center[..., 0] = img.shape[3] / 2  # x\n",
        "  center[..., 1] = img.shape[2] / 2  # y\n",
        "  if scale is None:\n",
        "    scale =  (torch.tensor([1,1])[None,:]).to(torch.float32).to(device)\n",
        "  M: torch.tensor = kornia.geometry.get_rotation_matrix2d(center, angle, scale)  # 1x2x3\n",
        "  _, _, h, w = img.shape\n",
        "  x_rotated: torch.tensor = kornia.geometry.warp_affine(img, M.to(device), dsize=(h, w))\n",
        "  translation = torch.cat((dx.unsqueeze(0), dy.unsqueeze(0))).unsqueeze(0) #torch.tensor([[dx, dy]], dtype=torch.float32, requires_grad=True)\n",
        "  out = kornia.geometry.translate(x_rotated, translation)\n",
        "  return out\n",
        "\n",
        "def add_circle_on_image(image, circle, alpha):\n",
        "  return image + alpha*circle\n"
      ],
      "metadata": {
        "id": "svBwQ-Em2bSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gt_img = url_to_tensor('https://cms.uni-konstanz.de/fileadmin/archive/informatik-saupe/fileadmin/informatik/ag-saupe/Webpages/lehre/dip_w0910/pictures/cameraman.tif', readFlag=cv2.IMREAD_COLOR)[:,:1,:,:]\n"
      ],
      "metadata": {
        "id": "4dDzgEioku1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_circles = 2000\n",
        "n_inner_opts = 200\n",
        "circles = torch.rand(n_circles, 2).to(device)"
      ],
      "metadata": {
        "id": "uPy-b9mrhkTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "6VW8YeT2kFs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: LR SPECIFID TO EACH PARAM\n",
        "# FIND IF ACTUALLY DOES ANYTHING IN THE INNER LOOP !!!!"
      ],
      "metadata": {
        "id": "TI5E0IkNJno5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = torch.zeros_like(gt_img).detach()\n",
        "best_error = criterion(gt_img, image).detach()\n",
        "size = image.shape\n",
        "\n",
        "for cid, wh in tqdm.tqdm(enumerate(circles), total=len(circles)):\n",
        "  wh = wh*torch.tensor(size[2:]).to(device)/1.5\n",
        "  dx_, dy_, alpha = torch.rand(3).to(device)\n",
        "  \n",
        "  dx = (0.5-dx_)*size[2]\n",
        "  dy = (0.5-dy_)*size[3]\n",
        "  rotation = 180*(0.5 - torch.rand(1).to(device))\n",
        "  scale = 2*(torch.rand(2).unsqueeze(0).to(device))\n",
        "  for member in [dx, dy, rotation, alpha, wh, scale]:\n",
        "    member.requires_grad = True\n",
        "\n",
        "  new_circle = draw_cricle(size, wh)[None,None,...].detach()\n",
        "  optimizer = optim.Adam([dx, dy, alpha, rotation, scale], lr=0.5)\n",
        "\n",
        "  for i in range(n_inner_opts):\n",
        "    optimizer.zero_grad()\n",
        "    new_circle_trans = translate_shape_img(new_circle.clone(), dx, dy, rotation, scale)\n",
        "    optional_image = torch.clip(add_circle_on_image(image, new_circle_trans, alpha), 0, 1)\n",
        "    tmp_error = criterion(gt_img, optional_image) \n",
        "    tmp_error.backward()\n",
        "    optimizer.step()\n",
        "  #imshow_tensor(optional_image.detach(), 'optional_img')\n",
        "\n",
        "  \n",
        "  if tmp_error < best_error:\n",
        "    print(f'found improvement: {best_error} to {tmp_error}')\n",
        "    print(f'dx: {dx.detach().cpu().numpy().ravel()[0]:.1f}, dy: {dy.detach().cpu().numpy().ravel()[0]:.1f}, wh: {wh.detach().cpu().numpy()}, alpha: {alpha.detach().cpu().numpy().ravel()[0]:.3f}')\n",
        "    image = optional_image.detach()\n",
        "    if cid%10==0: ####<<<<<<<<<<<<\n",
        "      imshow_tensor(optional_image.detach(), 'improved_img')\n",
        "\n",
        "    best_error = tmp_error"
      ],
      "metadata": {
        "id": "Anaij-C3gCt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[8,8])\n",
        "plt.imshow(np.hstack([image[0,0,:,:].cpu().numpy(), gt_img[0,0,:,:].cpu().numpy()]), vmin=0, vmax=1, cmap='gray')\n",
        "plt.axis(False)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "I3QKO2ShIei1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xrecCxS14vhA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}